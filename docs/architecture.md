# ğŸ“ Architecture Overview â€“ Ecommerce Monitoring ETL

## Objetivo do Projeto

Este projeto tem como objetivo coletar, estruturar, transformar e disponibilizar
dados de produtos do Mercado Livre para fins de anÃ¡lise de preÃ§os, vendas,
descontos e comportamento de mercado.

A arquitetura foi pensada para ser:
- simples
- escalÃ¡vel
- rastreÃ¡vel
- alinhada a boas prÃ¡ticas de engenharia de dados

## VisÃ£o Geral da Arquitetura

O projeto segue um modelo inspirado em **ELT (Extract, Load, Transform)**,
com separaÃ§Ã£o clara de responsabilidades entre coleta, armazenamento e tratamento
dos dados.

A estrutura principal Ã© dividida em:

- Drivers (coleta e parsing)
- Camada de dados (Bronze / Silver / Gold)
- TransformaÃ§Ãµes
- AnÃ¡lise (notebooks)

## Estrutura de Pastas

```text
ecommerce-monitoring-etl/
â”œâ”€â”€ src/                        # CÃ³digo-fonte principal da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ drivers/                # Conectores externos (HTTP Requester, Database Driver)
â”‚   â”œâ”€â”€ pipelines/              # OrquestraÃ§Ã£o dos fluxos (BronzePipeline, SilverPipeline)
â”‚   â”œâ”€â”€ transformations/        # Regras de negÃ³cio e limpeza (LÃ³gica de conversÃ£o/Regex)
â”‚   â”œâ”€â”€ utils/                  # FunÃ§Ãµes auxiliares (File handler, logs, formatadores)
â”‚   â”œâ”€â”€ models/                 # DefiniÃ§Ã£o de schemas e contratos de dados
â”‚   â””â”€â”€ config/                 # ConfiguraÃ§Ãµes globais, DB e VariÃ¡veis de ambiente
â”œâ”€â”€ data/                       # Nosso "Data Lake" local dividido por camadas
â”‚   â”œâ”€â”€ bronze/                     # Dados brutos (Raw JSON) - Origem da verdade
â”‚   â”œâ”€â”€ silver/                     # Dados limpos e tipados (Parquet) - Pronto para anÃ¡lise
â”‚   â””â”€â”€ gold/                       # Dados agregados e KPIs - Pronto para Dashboards
â”œâ”€â”€ notebooks/                  # Experimentos, anÃ¡lise exploratÃ³ria e prototipagem
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o tÃ©cnica, arquitetura e decisÃµes
â”œâ”€â”€ tests/                      # Testes unitÃ¡rios e de integraÃ§Ã£o (Garante a confiabilidade)
â”œâ”€â”€ main.py                     # Ponto de entrada do sistema
â”œâ”€â”€ Dockerfile                  # Receita para criar a imagem do container
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o do Python + Banco de Dados
â””â”€â”€ .env                        # VariÃ¡veis sensÃ­veis (Senhas, URLs, chaves)
```

## Drivers

A pasta `src/drivers` Ã© responsÃ¡vel pela **interaÃ§Ã£o com fontes externas**.

### HttpRequester
- Realiza requisiÃ§Ãµes HTTP
- Gerencia headers e sessÃ£o
- NÃ£o contÃ©m regras de negÃ³cio

### HtmlScrape (Parser)
- Converte HTML bruto em estruturas de dados
- Extrai apenas informaÃ§Ãµes visÃ­veis no HTML
- NÃ£o realiza normalizaÃ§Ãµes ou cÃ¡lculos analÃ­ticos

Essa separaÃ§Ã£o garante que mudanÃ§as na interface do site nÃ£o afetem diretamente as regras de negÃ³cio.

## Camada de Dados

O projeto utiliza o padrÃ£o medalhÃ£o (**Bronze / Silver / Gold**).

### Bronze ğŸ¥‰
- Dados crus, sem tratamento
- Representam exatamente o que foi coletado
- Servem como fonte de reprocessamento

Exemplos:
- `IngestÃ£o de dados` Os dados sÃ£o armazenados exatamente no formato original, sem transformaÃ§Ãµes complexas, mantendo a integridade original para auditoria.
- `HistorizaÃ§Ã£o Completa` MantÃ©m o histÃ³rico completo de dados. Se uma regra de negÃ³cio mudar no futuro, os dados da camada Bronze permitem reprocessar tudo desde o inÃ­cio.
- `AdiÃ§Ã£o de Metadados de IngestÃ£o` Acrescenta colunas de controle, como a hora de chegada do arquivo (timestamp), nome do arquivo de origem, e ID do processo de carga, facilitando a rastreabilidade (data lineage).
- `Isolamento para Reprocessamento` Atua como uma "rede de seguranÃ§a". Se houver erros nas camadas Silver ou Gold, os engenheiros podem usar a camada Bronze para recriar as camadas superiores sem precisar voltar aos sistemas de origem.
- `Gerenciamento de Schema Evolution` Consegue lidar com mudanÃ§as na estrutura dos dados de origem (novas colunas, etc.) sem interromper o pipeline de ingestÃ£o.

---

### Silver ğŸ¥ˆ
- Dados tratados e normalizados
- Tipos corrigidos (string â†’ nÃºmero)
- Campos derivados adicionados

Exemplos:
- `Limpeza e Conformidade` Padroniza formatos (datas, moedas), remove nulos indesejados, trata erros de ingesta e aplica regras de qualidade de dados.
- `DesduplicaÃ§Ã£o` Garante que cada registro seja Ãºnico, eliminando linhas duplicadas que surgiram durante o processo de extraÃ§Ã£o.
- `EstruturaÃ§Ã£o` Transforma arquivos semiestruturados, como JSON ou logs, em tabelas relacionais ou colunares estruturadas, facilitando a consulta.
- `Enriquecimento` Adiciona informaÃ§Ãµes contextuais aos dados, como geolocalizaÃ§Ã£o, cruzamento de chaves ou cÃ¡lculos prÃ©vios simples.
- `AplicaÃ§Ã£o de Schemas`: Define tipos de dados rigorosos (inteiro, string, timestamp) para garantir consistÃªncia antes da camada Gold.

---

### Gold ğŸ¥‡
- Dados prontos para anÃ¡lise e visualizaÃ§Ã£o
- AgregaÃ§Ãµes, rankings e mÃ©tricas
- Utilizados por dashboards e notebooks

## Transformations

A pasta `src/transformations` contÃ©m as regras de negÃ³cio e tratamentos de dados.

PrincÃ­pios adotados:
- Nenhuma transformaÃ§Ã£o ocorre na extraÃ§Ã£o
- Dados Bronze nunca sÃ£o modificados
- Toda regra Ã© explÃ­cita e rastreÃ¡vel

Exemplos de transformaÃ§Ãµes:
- conversÃ£o de "+10mil vendidos" â†’ 10000
- cÃ¡lculo de percentual de desconto
- padronizaÃ§Ã£o de preÃ§os com centavos

## Utils

A pasta `src/utils` contÃ©m funÃ§Ãµes auxiliares reutilizÃ¡veis,
como:
- parsing de textos
- conversÃ£o de valores monetÃ¡rios
- manipulaÃ§Ã£o de datas
- salvar para bronze
- salvar para silver

Essas funÃ§Ãµes nÃ£o dependem de uma fonte especÃ­fica.

## Models

A pasta `src/models` define contratos de dados, facilitando validaÃ§Ã£o, tipagem e padronizaÃ§Ã£o entre camadas.

## Notebooks

A pasta `notebooks/` Ã© utilizada exclusivamente para anÃ¡lise exploratÃ³ria, visualizaÃ§Ã£o e validaÃ§Ã£o dos dados.

Regras:
- notebooks nÃ£o realizam scraping
- notebooks nÃ£o alteram dados
- consomem apenas dados Silver ou Gold

## PrincÃ­pios Arquiteturais

- SeparaÃ§Ã£o de responsabilidades
- Rastreabilidade dos dados
- Facilidade de reprocessamento
- Clareza entre dado bruto e dado tratado
- Estrutura preparada para escalar com orquestradores (ex: Airflow)

## ConsideraÃ§Ãµes Finais

O projeto pode evoluir facilmente para:
- mÃºltiplas fontes
- execuÃ§Ã£o agendada
- integraÃ§Ã£o com data warehouses
